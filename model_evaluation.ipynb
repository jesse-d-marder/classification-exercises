{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0de34af5-a3f2-4d3c-ac21-f79cf6b77aae",
   "metadata": {},
   "source": [
    "### Exercises from https://ds.codeup.com/classification/evaluation/#exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d340abd7-4b5d-4c5c-bf0e-cef6fd0b0370",
   "metadata": {},
   "source": [
    "## EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "319088e8-2bbe-47d3-8856-6d7d08d93fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec575792-df31-4434-a944-4691cde9529e",
   "metadata": {},
   "source": [
    "### 2. Confusion matrix:\n",
    "|               | pred dog   | pred cat   |\n",
    "|:------------  |-----------:|-----------:|\n",
    "| actual dog    |         46 |         7  |\n",
    "| actual cat    |         13 |         34 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fc5b73-11a5-4b0e-b253-185240c156e7",
   "metadata": {},
   "source": [
    "False Positive: Predict cat but actually a dog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a1c271-0549-4c17-85f3-1932d2e681f2",
   "metadata": {},
   "source": [
    "False Negative: Predict dog but actually a cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ced4a1-bb17-43b9-99dd-f892f0dcea04",
   "metadata": {},
   "source": [
    "True Positive: Predicted cat and is a cat\n",
    "\n",
    "True Negative: Predicted dog and is a dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "000f627e-c2d9-4a21-b426-9427852ae12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = 7\n",
    "FN = 13\n",
    "TP = 34\n",
    "TN = 46"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7998db4f-1f35-4f8a-a755-9a6ec6c6e060",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "- **accuracy**: (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "- **precision**: TP / (TP + FP)\n",
    "\n",
    "- **recall**: TP / (TP + FN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c546b81c-2770-4fb9-ae85-1dac2a4ce7ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8, Precision: 0.8292682926829268, Recall: 0.723404255319149\n"
     ]
    }
   ],
   "source": [
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5239b794-0dc7-4f13-89e2-d9e5da569099",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Rubber ducks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a32830a8-a21f-404e-9a3e-9139a486ecfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>No Defect</td>\n",
       "      <td>Defect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        actual     model1     model2     model3\n",
       "0    No Defect  No Defect     Defect  No Defect\n",
       "1    No Defect  No Defect     Defect     Defect\n",
       "2    No Defect  No Defect     Defect  No Defect\n",
       "3    No Defect     Defect     Defect     Defect\n",
       "4    No Defect  No Defect     Defect  No Defect\n",
       "..         ...        ...        ...        ...\n",
       "195  No Defect  No Defect     Defect     Defect\n",
       "196     Defect     Defect  No Defect  No Defect\n",
       "197  No Defect  No Defect  No Defect  No Defect\n",
       "198  No Defect  No Defect     Defect     Defect\n",
       "199  No Defect  No Defect  No Defect     Defect\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "df = pd.read_csv('c3.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e349bf-0645-4e8d-b3ca-6184681a4956",
   "metadata": {},
   "source": [
    "### Want to identify as many ducks with defect as possible. Which metric to use?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d9fb88-b603-4e9e-849e-67c7f7ba7bbc",
   "metadata": {},
   "source": [
    "- Positive: defect\n",
    "- Negative: no defect\n",
    "\n",
    "- False positive: predict defect but no defect\n",
    "- False negative: predict no defect but defect\n",
    "\n",
    "Less worried about false positives, more concerned abour false negatives!!! Don't want to let a defective duck slip by...\n",
    "\n",
    "###  -> USE RECALL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660bb2b5-2d6b-400e-800a-ed349838faa3",
   "metadata": {},
   "source": [
    "### Which model to go with?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37e1be98-f316-4772-8876-300ab62ffac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model1\n",
      "   model accuracy: 95.00%\n",
      "\n",
      "   model recall: 50.00%\n",
      "\n",
      "model precision: 80.00%\n",
      "--------\n",
      "model2\n",
      "   model accuracy: 56.00%\n",
      "\n",
      "   model recall: 56.25%\n",
      "\n",
      "model precision: 10.00%\n",
      "--------\n",
      "model3\n",
      "   model accuracy: 55.50%\n",
      "\n",
      "   model recall: 81.25%\n",
      "\n",
      "model precision: 13.13%\n",
      "--------\n",
      "The model with the highest recall is model3\n",
      "The model with the highest precision is model1\n"
     ]
    }
   ],
   "source": [
    "positive = 'Defect'\n",
    "models = ['model1','model2','model3']\n",
    "recalls={}\n",
    "precisions={}\n",
    "for model in models:\n",
    "    \n",
    "    # accuracy -- overall hit rate\n",
    "    model_accuracy = (df[model]== df.actual).mean()\n",
    "    # baseline_accuracy = (df.baseline == df.actual).mean()\n",
    "\n",
    "    # precision -- how good are our positive predictions?\n",
    "    # precision -- model performance | predicted positive\n",
    "    subset = df[df[model] == positive]\n",
    "    model_precision = (subset[model] == subset.actual).mean()\n",
    "    precisions[model] = model_precision\n",
    "    # subset = df[df.baseline == positive]\n",
    "    # baseline_precision = (subset.baseline == subset.actual).mean()\n",
    "\n",
    "    # recall -- how good are we at detecting actual positives?\n",
    "    # recall -- model performance | actual positive\n",
    "    subset = df[df.actual == positive]\n",
    "    model_recall = (subset[model] == subset.actual).mean()\n",
    "    recalls[model]=model_recall\n",
    "    # baseline_recall = (subset.baseline == subset.actual).mean()\n",
    "\n",
    "    print(f'{model}')\n",
    "    print(f'   model accuracy: {model_accuracy:.2%}')\n",
    "    # print(f'baseline accuracy: {baseline_accuracy:.2%}')\n",
    "    print()\n",
    "    print(f'   model recall: {model_recall:.2%}')\n",
    "    # print(f'baseline recall: {baseline_recall:.2%}')\n",
    "    print()\n",
    "    print(f'model precision: {model_precision:.2%}')\n",
    "    # print(f'baseline precision: {baseline_precision:.2%}')\n",
    "    print('--------')\n",
    "\n",
    "print(f'The model with the highest recall is {max(recalls, key = recalls.get)}')\n",
    "print(f'The model with the highest precision is {max(precisions, key = precisions.get)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0a147f-7e7a-419b-ae04-881d907a2437",
   "metadata": {},
   "source": [
    "## -> USE MODEL 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c4f623-54d8-4d95-baaf-70ff118eec44",
   "metadata": {},
   "source": [
    "### Going to give a vacation for those with defective duck\n",
    "### Really don't want to accidentally give someone a vacation package if it's not defective\n",
    "#### Reminder that false positive is predict positive but actually negative, false negative is predict no defect but actually is defective\n",
    "#### False positive is more expensive -> optimize for precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eaa644a4-4aa9-4d8b-9573-e62d4a7092ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model with the highest precision is model1\n"
     ]
    }
   ],
   "source": [
    "print(f'The model with the highest precision is {max(precisions, key = precisions.get)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb721500-2e5f-4023-9759-3e944ac664b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python397jvsc74a57bd038cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
